{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "! pip install PyPDF2\n",
        "! pip install chromadb\n",
        "! pip install tavily\n",
        "! pip install nemoguardrails"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "uAqnrBsRqOdU",
        "outputId": "384e06d6-1091-49a0-81ec-fbb8d79186db"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: PyPDF2 in /usr/local/lib/python3.12/dist-packages (3.0.1)\n",
            "Requirement already satisfied: chromadb in /usr/local/lib/python3.12/dist-packages (1.3.5)\n",
            "Requirement already satisfied: build>=1.0.3 in /usr/local/lib/python3.12/dist-packages (from chromadb) (1.3.0)\n",
            "Requirement already satisfied: pydantic>=1.9 in /usr/local/lib/python3.12/dist-packages (from chromadb) (2.11.10)\n",
            "Requirement already satisfied: pybase64>=1.4.1 in /usr/local/lib/python3.12/dist-packages (from chromadb) (1.4.2)\n",
            "Requirement already satisfied: uvicorn>=0.18.3 in /usr/local/lib/python3.12/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.38.0)\n",
            "Requirement already satisfied: numpy>=1.22.5 in /usr/local/lib/python3.12/dist-packages (from chromadb) (2.0.2)\n",
            "Requirement already satisfied: posthog<6.0.0,>=2.4.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (5.4.0)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (4.15.0)\n",
            "Requirement already satisfied: onnxruntime>=1.14.1 in /usr/local/lib/python3.12/dist-packages (from chromadb) (1.23.2)\n",
            "Requirement already satisfied: opentelemetry-api>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (1.38.0)\n",
            "Requirement already satisfied: opentelemetry-exporter-otlp-proto-grpc>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (1.38.0)\n",
            "Requirement already satisfied: opentelemetry-sdk>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (1.38.0)\n",
            "Requirement already satisfied: tokenizers>=0.13.2 in /usr/local/lib/python3.12/dist-packages (from chromadb) (0.22.1)\n",
            "Requirement already satisfied: pypika>=0.48.9 in /usr/local/lib/python3.12/dist-packages (from chromadb) (0.48.9)\n",
            "Requirement already satisfied: tqdm>=4.65.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (4.67.1)\n",
            "Requirement already satisfied: overrides>=7.3.1 in /usr/local/lib/python3.12/dist-packages (from chromadb) (7.7.0)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.12/dist-packages (from chromadb) (6.5.2)\n",
            "Requirement already satisfied: grpcio>=1.58.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (1.76.0)\n",
            "Requirement already satisfied: bcrypt>=4.0.1 in /usr/local/lib/python3.12/dist-packages (from chromadb) (5.0.0)\n",
            "Requirement already satisfied: typer>=0.9.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (0.20.0)\n",
            "Requirement already satisfied: kubernetes>=28.1.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (34.1.0)\n",
            "Requirement already satisfied: tenacity>=8.2.3 in /usr/local/lib/python3.12/dist-packages (from chromadb) (8.5.0)\n",
            "Requirement already satisfied: pyyaml>=6.0.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (6.0.3)\n",
            "Requirement already satisfied: mmh3>=4.0.1 in /usr/local/lib/python3.12/dist-packages (from chromadb) (5.2.0)\n",
            "Requirement already satisfied: orjson>=3.9.12 in /usr/local/lib/python3.12/dist-packages (from chromadb) (3.11.4)\n",
            "Requirement already satisfied: httpx>=0.27.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (0.28.1)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (13.9.4)\n",
            "Requirement already satisfied: jsonschema>=4.19.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (4.25.1)\n",
            "Requirement already satisfied: packaging>=19.1 in /usr/local/lib/python3.12/dist-packages (from build>=1.0.3->chromadb) (25.0)\n",
            "Requirement already satisfied: pyproject_hooks in /usr/local/lib/python3.12/dist-packages (from build>=1.0.3->chromadb) (1.2.0)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx>=0.27.0->chromadb) (4.11.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx>=0.27.0->chromadb) (2025.11.12)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx>=0.27.0->chromadb) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from httpx>=0.27.0->chromadb) (3.11)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx>=0.27.0->chromadb) (0.16.0)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.19.0->chromadb) (25.4.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.19.0->chromadb) (2025.9.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.19.0->chromadb) (0.37.0)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.19.0->chromadb) (0.29.0)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb) (1.17.0)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb) (2.9.0.post0)\n",
            "Requirement already satisfied: google-auth>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb) (2.38.0)\n",
            "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb) (1.9.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb) (2.32.5)\n",
            "Requirement already satisfied: requests-oauthlib in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb) (2.0.0)\n",
            "Requirement already satisfied: urllib3<2.4.0,>=1.24.2 in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb) (2.3.0)\n",
            "Requirement already satisfied: durationpy>=0.7 in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb) (0.10)\n",
            "Requirement already satisfied: coloredlogs in /usr/local/lib/python3.12/dist-packages (from onnxruntime>=1.14.1->chromadb) (15.0.1)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.12/dist-packages (from onnxruntime>=1.14.1->chromadb) (25.9.23)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.12/dist-packages (from onnxruntime>=1.14.1->chromadb) (5.29.5)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.12/dist-packages (from onnxruntime>=1.14.1->chromadb) (1.13.3)\n",
            "Requirement already satisfied: importlib-metadata<8.8.0,>=6.0 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-api>=1.2.0->chromadb) (8.7.0)\n",
            "Requirement already satisfied: googleapis-common-protos~=1.57 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.72.0)\n",
            "Requirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.38.0 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.38.0)\n",
            "Requirement already satisfied: opentelemetry-proto==1.38.0 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.38.0)\n",
            "Requirement already satisfied: opentelemetry-semantic-conventions==0.59b0 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-sdk>=1.2.0->chromadb) (0.59b0)\n",
            "Requirement already satisfied: backoff>=1.10.0 in /usr/local/lib/python3.12/dist-packages (from posthog<6.0.0,>=2.4.0->chromadb) (2.2.1)\n",
            "Requirement already satisfied: distro>=1.5.0 in /usr/local/lib/python3.12/dist-packages (from posthog<6.0.0,>=2.4.0->chromadb) (1.9.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic>=1.9->chromadb) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic>=1.9->chromadb) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic>=1.9->chromadb) (0.4.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->chromadb) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->chromadb) (2.19.2)\n",
            "Requirement already satisfied: huggingface-hub<2.0,>=0.16.4 in /usr/local/lib/python3.12/dist-packages (from tokenizers>=0.13.2->chromadb) (0.36.0)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.12/dist-packages (from typer>=0.9.0->chromadb) (8.3.1)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from typer>=0.9.0->chromadb) (1.5.4)\n",
            "Requirement already satisfied: httptools>=0.6.3 in /usr/local/lib/python3.12/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.7.1)\n",
            "Requirement already satisfied: python-dotenv>=0.13 in /usr/local/lib/python3.12/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (1.2.1)\n",
            "Requirement already satisfied: uvloop>=0.15.1 in /usr/local/lib/python3.12/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.22.1)\n",
            "Requirement already satisfied: watchfiles>=0.13 in /usr/local/lib/python3.12/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (1.1.1)\n",
            "Requirement already satisfied: websockets>=10.4 in /usr/local/lib/python3.12/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (15.0.1)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.12/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (4.9.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (3.20.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (2025.3.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (1.2.0)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.12/dist-packages (from importlib-metadata<8.8.0,>=6.0->opentelemetry-api>=1.2.0->chromadb) (3.23.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->chromadb) (0.1.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->kubernetes>=28.1.0->chromadb) (3.4.4)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio->httpx>=0.27.0->chromadb) (1.3.1)\n",
            "Requirement already satisfied: humanfriendly>=9.1 in /usr/local/lib/python3.12/dist-packages (from coloredlogs->onnxruntime>=1.14.1->chromadb) (10.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.12/dist-packages (from requests-oauthlib->kubernetes>=28.1.0->chromadb) (3.3.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy->onnxruntime>=1.14.1->chromadb) (1.3.0)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.12/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.6.1)\n",
            "Requirement already satisfied: tavily in /usr/local/lib/python3.12/dist-packages (1.1.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from tavily) (2.32.5)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.12/dist-packages (from tavily) (3.13.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->tavily) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->tavily) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->tavily) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp->tavily) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp->tavily) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->tavily) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->tavily) (1.22.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->tavily) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->tavily) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->tavily) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->tavily) (2025.11.12)\n",
            "Requirement already satisfied: typing-extensions>=4.2 in /usr/local/lib/python3.12/dist-packages (from aiosignal>=1.4.0->aiohttp->tavily) (4.15.0)\n",
            "Requirement already satisfied: nemoguardrails in /usr/local/lib/python3.12/dist-packages (0.18.0)\n",
            "Requirement already satisfied: aiohttp>=3.10.11 in /usr/local/lib/python3.12/dist-packages (from nemoguardrails) (3.13.2)\n",
            "Requirement already satisfied: annoy>=1.17.3 in /usr/local/lib/python3.12/dist-packages (from nemoguardrails) (1.17.3)\n",
            "Requirement already satisfied: fastapi>=0.103.0 in /usr/local/lib/python3.12/dist-packages (from nemoguardrails) (0.121.3)\n",
            "Requirement already satisfied: fastembed<=0.6.0,>=0.2.2 in /usr/local/lib/python3.12/dist-packages (from nemoguardrails) (0.6.0)\n",
            "Requirement already satisfied: httpx>=0.24.1 in /usr/local/lib/python3.12/dist-packages (from nemoguardrails) (0.28.1)\n",
            "Requirement already satisfied: jinja2>=3.1.6 in /usr/local/lib/python3.12/dist-packages (from nemoguardrails) (3.1.6)\n",
            "Requirement already satisfied: langchain<0.4.0,>=0.2.14 in /usr/local/lib/python3.12/dist-packages (from nemoguardrails) (0.3.27)\n",
            "Requirement already satisfied: langchain-community<0.4.0,>=0.2.5 in /usr/local/lib/python3.12/dist-packages (from nemoguardrails) (0.3.31)\n",
            "Requirement already satisfied: langchain-core<0.4.0,>=0.2.14 in /usr/local/lib/python3.12/dist-packages (from nemoguardrails) (0.3.80)\n",
            "Requirement already satisfied: lark>=1.1.7 in /usr/local/lib/python3.12/dist-packages (from nemoguardrails) (1.3.1)\n",
            "Requirement already satisfied: nest-asyncio>=1.5.6 in /usr/local/lib/python3.12/dist-packages (from nemoguardrails) (1.6.0)\n",
            "Requirement already satisfied: pandas<3,>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from nemoguardrails) (2.2.2)\n",
            "Requirement already satisfied: prompt-toolkit>=3.0 in /usr/local/lib/python3.12/dist-packages (from nemoguardrails) (3.0.52)\n",
            "Requirement already satisfied: protobuf>=5.29.5 in /usr/local/lib/python3.12/dist-packages (from nemoguardrails) (5.29.5)\n",
            "Requirement already satisfied: pydantic>=1.10 in /usr/local/lib/python3.12/dist-packages (from nemoguardrails) (2.11.10)\n",
            "Requirement already satisfied: pyyaml>=6.0 in /usr/local/lib/python3.12/dist-packages (from nemoguardrails) (6.0.3)\n",
            "Requirement already satisfied: rich>=13.5.2 in /usr/local/lib/python3.12/dist-packages (from nemoguardrails) (13.9.4)\n",
            "Requirement already satisfied: simpleeval>=0.9.13 in /usr/local/lib/python3.12/dist-packages (from nemoguardrails) (1.0.3)\n",
            "Requirement already satisfied: starlette>=0.49.1 in /usr/local/lib/python3.12/dist-packages (from nemoguardrails) (0.50.0)\n",
            "Requirement already satisfied: typer>=0.8 in /usr/local/lib/python3.12/dist-packages (from nemoguardrails) (0.20.0)\n",
            "Requirement already satisfied: uvicorn>=0.23 in /usr/local/lib/python3.12/dist-packages (from nemoguardrails) (0.38.0)\n",
            "Requirement already satisfied: watchdog>=3.0.0 in /usr/local/lib/python3.12/dist-packages (from nemoguardrails) (6.0.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp>=3.10.11->nemoguardrails) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp>=3.10.11->nemoguardrails) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp>=3.10.11->nemoguardrails) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp>=3.10.11->nemoguardrails) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp>=3.10.11->nemoguardrails) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp>=3.10.11->nemoguardrails) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp>=3.10.11->nemoguardrails) (1.22.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.12/dist-packages (from fastapi>=0.103.0->nemoguardrails) (4.15.0)\n",
            "Requirement already satisfied: annotated-doc>=0.0.2 in /usr/local/lib/python3.12/dist-packages (from fastapi>=0.103.0->nemoguardrails) (0.0.4)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.20 in /usr/local/lib/python3.12/dist-packages (from fastembed<=0.6.0,>=0.2.2->nemoguardrails) (0.36.0)\n",
            "Requirement already satisfied: loguru<0.8.0,>=0.7.2 in /usr/local/lib/python3.12/dist-packages (from fastembed<=0.6.0,>=0.2.2->nemoguardrails) (0.7.3)\n",
            "Requirement already satisfied: mmh3<6.0.0,>=4.1.0 in /usr/local/lib/python3.12/dist-packages (from fastembed<=0.6.0,>=0.2.2->nemoguardrails) (5.2.0)\n",
            "Requirement already satisfied: numpy>=1.26 in /usr/local/lib/python3.12/dist-packages (from fastembed<=0.6.0,>=0.2.2->nemoguardrails) (2.0.2)\n",
            "Requirement already satisfied: onnxruntime!=1.20.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from fastembed<=0.6.0,>=0.2.2->nemoguardrails) (1.23.2)\n",
            "Requirement already satisfied: pillow<12.0.0,>=10.3.0 in /usr/local/lib/python3.12/dist-packages (from fastembed<=0.6.0,>=0.2.2->nemoguardrails) (11.3.0)\n",
            "Requirement already satisfied: py-rust-stemmers<0.2.0,>=0.1.0 in /usr/local/lib/python3.12/dist-packages (from fastembed<=0.6.0,>=0.2.2->nemoguardrails) (0.1.5)\n",
            "Requirement already satisfied: requests<3.0,>=2.31 in /usr/local/lib/python3.12/dist-packages (from fastembed<=0.6.0,>=0.2.2->nemoguardrails) (2.32.5)\n",
            "Requirement already satisfied: tokenizers<1.0,>=0.15 in /usr/local/lib/python3.12/dist-packages (from fastembed<=0.6.0,>=0.2.2->nemoguardrails) (0.22.1)\n",
            "Requirement already satisfied: tqdm<5.0,>=4.66 in /usr/local/lib/python3.12/dist-packages (from fastembed<=0.6.0,>=0.2.2->nemoguardrails) (4.67.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx>=0.24.1->nemoguardrails) (4.11.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx>=0.24.1->nemoguardrails) (2025.11.12)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx>=0.24.1->nemoguardrails) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from httpx>=0.24.1->nemoguardrails) (3.11)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx>=0.24.1->nemoguardrails) (0.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2>=3.1.6->nemoguardrails) (3.0.3)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.9 in /usr/local/lib/python3.12/dist-packages (from langchain<0.4.0,>=0.2.14->nemoguardrails) (0.3.11)\n",
            "Requirement already satisfied: langsmith>=0.1.17 in /usr/local/lib/python3.12/dist-packages (from langchain<0.4.0,>=0.2.14->nemoguardrails) (0.4.43)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.12/dist-packages (from langchain<0.4.0,>=0.2.14->nemoguardrails) (2.0.44)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain-community<0.4.0,>=0.2.5->nemoguardrails) (8.5.0)\n",
            "Requirement already satisfied: dataclasses-json<0.7.0,>=0.6.7 in /usr/local/lib/python3.12/dist-packages (from langchain-community<0.4.0,>=0.2.5->nemoguardrails) (0.6.7)\n",
            "Requirement already satisfied: pydantic-settings<3.0.0,>=2.10.1 in /usr/local/lib/python3.12/dist-packages (from langchain-community<0.4.0,>=0.2.5->nemoguardrails) (2.12.0)\n",
            "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from langchain-community<0.4.0,>=0.2.5->nemoguardrails) (0.4.3)\n",
            "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<0.4.0,>=0.2.14->nemoguardrails) (1.33)\n",
            "Requirement already satisfied: packaging<26.0.0,>=23.2.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<0.4.0,>=0.2.14->nemoguardrails) (25.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas<3,>=1.4.0->nemoguardrails) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas<3,>=1.4.0->nemoguardrails) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas<3,>=1.4.0->nemoguardrails) (2025.2)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.12/dist-packages (from prompt-toolkit>=3.0->nemoguardrails) (0.2.14)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic>=1.10->nemoguardrails) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic>=1.10->nemoguardrails) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic>=1.10->nemoguardrails) (0.4.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich>=13.5.2->nemoguardrails) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich>=13.5.2->nemoguardrails) (2.19.2)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.12/dist-packages (from typer>=0.8->nemoguardrails) (8.3.1)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from typer>=0.8->nemoguardrails) (1.5.4)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio->httpx>=0.24.1->nemoguardrails) (1.3.1)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.12/dist-packages (from dataclasses-json<0.7.0,>=0.6.7->langchain-community<0.4.0,>=0.2.5->nemoguardrails) (3.26.1)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from dataclasses-json<0.7.0,>=0.6.7->langchain-community<0.4.0,>=0.2.5->nemoguardrails) (0.9.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.20->fastembed<=0.6.0,>=0.2.2->nemoguardrails) (3.20.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.20->fastembed<=0.6.0,>=0.2.2->nemoguardrails) (2025.3.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.20->fastembed<=0.6.0,>=0.2.2->nemoguardrails) (1.2.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<0.4.0,>=0.2.14->nemoguardrails) (3.0.0)\n",
            "Requirement already satisfied: orjson>=3.9.14 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.17->langchain<0.4.0,>=0.2.14->nemoguardrails) (3.11.4)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.17->langchain<0.4.0,>=0.2.14->nemoguardrails) (1.0.0)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.17->langchain<0.4.0,>=0.2.14->nemoguardrails) (0.25.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich>=13.5.2->nemoguardrails) (0.1.2)\n",
            "Requirement already satisfied: coloredlogs in /usr/local/lib/python3.12/dist-packages (from onnxruntime!=1.20.0,>=1.17.0->fastembed<=0.6.0,>=0.2.2->nemoguardrails) (15.0.1)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.12/dist-packages (from onnxruntime!=1.20.0,>=1.17.0->fastembed<=0.6.0,>=0.2.2->nemoguardrails) (25.9.23)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.12/dist-packages (from onnxruntime!=1.20.0,>=1.17.0->fastembed<=0.6.0,>=0.2.2->nemoguardrails) (1.13.3)\n",
            "Requirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.12/dist-packages (from pydantic-settings<3.0.0,>=2.10.1->langchain-community<0.4.0,>=0.2.5->nemoguardrails) (1.2.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas<3,>=1.4.0->nemoguardrails) (1.17.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3.0,>=2.31->fastembed<=0.6.0,>=0.2.2->nemoguardrails) (3.4.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3.0,>=2.31->fastembed<=0.6.0,>=0.2.2->nemoguardrails) (2.3.0)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from SQLAlchemy<3,>=1.4->langchain<0.4.0,>=0.2.14->nemoguardrails) (3.2.4)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7.0,>=0.6.7->langchain-community<0.4.0,>=0.2.5->nemoguardrails) (1.1.0)\n",
            "Requirement already satisfied: humanfriendly>=9.1 in /usr/local/lib/python3.12/dist-packages (from coloredlogs->onnxruntime!=1.20.0,>=1.17.0->fastembed<=0.6.0,>=0.2.2->nemoguardrails) (10.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy->onnxruntime!=1.20.0,>=1.17.0->fastembed<=0.6.0,>=0.2.2->nemoguardrails) (1.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "2k6RGXNUoTZf"
      },
      "outputs": [],
      "source": [
        "from openai import OpenAI\n",
        "import gradio as gr\n",
        "import os\n",
        "import PyPDF2\n",
        "import chromadb\n",
        "from dotenv import load_dotenv\n",
        "load_dotenv()\n",
        "import requests\n",
        "from urllib.parse import urlparse\n",
        "import re\n",
        "import json\n",
        "from datetime import datetime\n",
        "import uuid"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ[\"OPENAI_API_KEY\"] = \"\" #Add your OPENAI API Key\n",
        "load_dotenv()\n",
        "from openai import OpenAI\n",
        "client = OpenAI(api_key=\"\")"
      ],
      "metadata": {
        "id": "4-RJl90aqRK1"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# LangSmith imports with error handling\n",
        "os.environ[\"LANGCHAIN_API_KEY\"] = \"\"  #Add your LANGCHAIN API Key\n",
        "try:\n",
        "    import langsmith\n",
        "    from langsmith import traceable\n",
        "    LANGCHAIN_API_KEY = os.getenv(\"LANGCHAIN_API_KEY\")\n",
        "    if LANGCHAIN_API_KEY:\n",
        "        os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
        "        os.environ[\"LANGCHAIN_PROJECT\"] = \"physics-teacher-bot\"\n",
        "        langsmith_client = langsmith.Client()\n",
        "        LANGCHAIN_AVAILABLE = True\n",
        "        print(\"âœ… LangSmith tracing initialized successfully!\")\n",
        "    else:\n",
        "        print(\"âš ï¸  LANGCHAIN_API_KEY not found. LangSmith tracing will be disabled.\")\n",
        "        langsmith_client = None\n",
        "        LANGCHAIN_AVAILABLE = False\n",
        "except ImportError:\n",
        "    print(\"âš ï¸  LangSmith not installed. Tracing will be disabled.\")\n",
        "    print(\"ðŸ’¡ Run: pip install langsmith\")\n",
        "    langsmith_client = None\n",
        "    LANGCHAIN_AVAILABLE = False\n",
        "except Exception as e:\n",
        "    print(f\"âš ï¸  LangSmith initialization failed: {e}\")\n",
        "    langsmith_client = None\n",
        "    LANGCHAIN_AVAILABLE = False"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M7u4EM9BFtZA",
        "outputId": "87d01706-8862-4b6d-968d-04c52c10f1ce"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… LangSmith tracing initialized successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize Tavily client with error handling\n",
        "os.environ[\"TAVILY_API_KEY\"] = \"\"  #Add your TAVILY API Key\n",
        "try:\n",
        "    from tavily import TavilyClient\n",
        "    tavily_client = TavilyClient(api_key=os.getenv(\"TAVILY_API_KEY\"))\n",
        "    TAVILY_AVAILABLE = True\n",
        "except ImportError:\n",
        "    TAVILY_AVAILABLE = False\n",
        "    print(\"âš ï¸  Tavily not installed. Web search functionality will be disabled.\")\n",
        "    print(\"ðŸ’¡ Run: pip install tavily-python\")"
      ],
      "metadata": {
        "id": "CPfPUHSzquDh"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize NVIDIA NeMo Guardrails with error handling\n",
        "try:\n",
        "    from nemoguardrails import RailsConfig, LLMRails\n",
        "    from nemoguardrails.actions import action\n",
        "    NEMO_GUARDRAILS_AVAILABLE = True\n",
        "except ImportError:\n",
        "    NEMO_GUARDRAILS_AVAILABLE = False\n",
        "    print(\"âš ï¸  NVIDIA NeMo Guardrails not installed. Safety features will be disabled.\")\n",
        "    print(\"ðŸ’¡ Run: pip install nemoguardrails\")"
      ],
      "metadata": {
        "id": "HHBbzzs9qJpo"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize ChromaDB\n",
        "chroma_client = chromadb.Client()\n",
        "pdf_collection = chroma_client.create_collection(name=\"PhysicsPDFs\")\n",
        "memory_collection = chroma_client.create_collection(name=\"ConversationMemory\")"
      ],
      "metadata": {
        "id": "lNVPtxo_qwko",
        "collapsed": true
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize NeMo Guardrails if available\n",
        "nemo_rails = None\n",
        "if NEMO_GUARDRAILS_AVAILABLE:\n",
        "    try:\n",
        "        # Define complete guardrails configuration\n",
        "        guardrails_config = \"\"\"\n",
        "models:\n",
        "  - type: main\n",
        "    engine: openai\n",
        "    model: gpt-3.5-turbo\n",
        "\n",
        "rails:\n",
        "  input:\n",
        "    flows:\n",
        "      - self check input\n",
        "      - check jailbreak\n",
        "      - detect sensitive topics\n",
        "  output:\n",
        "    flows:\n",
        "      - self check output\n",
        "      - check for pii\n",
        "      - ensure appropriate tone\n",
        "\n",
        "instructions:\n",
        "  - type: general\n",
        "    content: |\n",
        "      You are a physics teaching assistant. Always provide accurate, educational,\n",
        "      and safe responses. Focus on physics concepts and related scientific topics.\n",
        "      Avoid harmful, dangerous, or inappropriate content.\n",
        "\n",
        "prompts:\n",
        "  - task: self_check_input\n",
        "    content: |\n",
        "      Check if the following user message is safe and appropriate for a physics education context.\n",
        "      Consider if it contains any harmful, dangerous, illegal, or inappropriate content.\n",
        "      Focus on educational physics topics.\n",
        "\n",
        "      User message: {{user_input}}\n",
        "\n",
        "      Is this message safe and appropriate? Answer with YES or NO only.\n",
        "\n",
        "  - task: self_check_output\n",
        "    content: |\n",
        "      Check if the following bot response is safe, appropriate, and follows the guidelines for a physics education context.\n",
        "      The response should be educational, accurate, and avoid any harmful or inappropriate content.\n",
        "\n",
        "      Bot response: {{bot_response}}\n",
        "\n",
        "      Is this response safe and appropriate? Answer with YES or NO only.\n",
        "\n",
        "  - task: general\n",
        "    content: |\n",
        "      You are a physics teaching assistant. Provide accurate, educational, and safe responses.\n",
        "      Focus on physics concepts and related scientific topics.\n",
        "      If asked about harmful, dangerous, or inappropriate topics, politely decline and redirect to educational physics topics.\n",
        "        \"\"\"\n",
        "\n",
        "        config = RailsConfig.from_content(guardrails_config)\n",
        "        nemo_rails = LLMRails(config)\n",
        "\n",
        "        # Register custom actions\n",
        "        @action\n",
        "        def check_physics_context():\n",
        "            return True\n",
        "\n",
        "        @action\n",
        "        def validate_educational_content():\n",
        "            return True\n",
        "\n",
        "        nemo_rails.register_action(check_physics_context)\n",
        "        nemo_rails.register_action(validate_educational_content)\n",
        "\n",
        "        print(\"âœ… NVIDIA NeMo Guardrails initialized successfully!\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"âŒ Error initializing NeMo Guardrails: {e}\")\n",
        "        NEMO_GUARDRAILS_AVAILABLE = False"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vAwu_fIiqUb1",
        "outputId": "085837ef-481f-4fd3-e3c8-1f08911861f1"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:nemoguardrails.rails.llm.llmrails:No main LLM specified in the config and no LLM provided via constructor.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… NVIDIA NeMo Guardrails initialized successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class TokenUsageTracker:\n",
        "    \"\"\"Track token usage across different components\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        self.total_tokens = 0\n",
        "        self.prompt_tokens = 0\n",
        "        self.completion_tokens = 0\n",
        "        self.costs = 0.0\n",
        "\n",
        "    def update_from_response(self, response, model=\"gpt-3.5-turbo\"):\n",
        "        \"\"\"Update token counts from OpenAI response\"\"\"\n",
        "        if hasattr(response, 'usage'):\n",
        "            usage = response.usage\n",
        "            self.prompt_tokens += getattr(usage, 'prompt_tokens', 0)\n",
        "            self.completion_tokens += getattr(usage, 'completion_tokens', 0)\n",
        "            self.total_tokens += getattr(usage, 'total_tokens', 0)\n",
        "\n",
        "            # Calculate cost (approximate)\n",
        "            cost_rates = {\n",
        "                \"gpt-3.5-turbo\": (0.0015, 0.002),  # $0.0015/1K input, $0.002/1K output\n",
        "                \"gpt-4\": (0.03, 0.06),  # $0.03/1K input, $0.06/1K output\n",
        "                \"gpt-4-turbo\": (0.01, 0.03)  # $0.01/1K input, $0.03/1K output\n",
        "            }\n",
        "\n",
        "            input_rate, output_rate = cost_rates.get(model, (0.0015, 0.002))\n",
        "            self.costs += (self.prompt_tokens / 1000 * input_rate) + (self.completion_tokens / 1000 * output_rate)\n",
        "\n",
        "    def get_summary(self):\n",
        "        \"\"\"Get token usage summary\"\"\"\n",
        "        return {\n",
        "            \"total_tokens\": self.total_tokens,\n",
        "            \"prompt_tokens\": self.prompt_tokens,\n",
        "            \"completion_tokens\": self.completion_tokens,\n",
        "            \"estimated_cost\": round(self.costs, 4)\n",
        "        }"
      ],
      "metadata": {
        "id": "QlzXqaz1aKSL"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Global token tracker\n",
        "token_tracker = TokenUsageTracker()\n",
        "\n",
        "def traceable_function(func):\n",
        "    \"\"\"Decorator that conditionally applies tracing based on availability\"\"\"\n",
        "    if LANGCHAIN_AVAILABLE:\n",
        "        return traceable(func)\n",
        "    return func"
      ],
      "metadata": {
        "id": "onKuDr8uaNaj"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@traceable_function\n",
        "def extract_text_from_pdf(pdf_path):\n",
        "    \"\"\"Extract text from PDF file\"\"\"\n",
        "    with open(pdf_path, 'rb') as file:\n",
        "        reader = PyPDF2.PdfReader(file)\n",
        "        text = \"\"\n",
        "        for page in reader.pages:\n",
        "            text += page.extract_text() + \"\\n\"\n",
        "    return text"
      ],
      "metadata": {
        "id": "oBOB-Or_q2iR"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@traceable_function\n",
        "def chunk_text(text, chunk_size=1000):\n",
        "    \"\"\"Split text into chunks\"\"\"\n",
        "    words = text.split()\n",
        "    chunks = []\n",
        "    for i in range(0, len(words), chunk_size):\n",
        "        chunk = \" \".join(words[i:i + chunk_size])\n",
        "        chunks.append(chunk)\n",
        "    return chunks"
      ],
      "metadata": {
        "id": "P3RXAKPqq55N"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@traceable_function\n",
        "def store_pdf_in_db(pdf_path):\n",
        "    \"\"\"Extract, chunk and store PDF in ChromaDB\"\"\"\n",
        "    try:\n",
        "        text = extract_text_from_pdf(pdf_path)\n",
        "        chunks = chunk_text(text)\n",
        "\n",
        "        # Clear existing data\n",
        "        pdf_collection.delete(where={\"source\": {\"$ne\": \"\"}})\n",
        "\n",
        "        # Add chunks to ChromaDB\n",
        "        for i, chunk in enumerate(chunks):\n",
        "            pdf_collection.add(\n",
        "                documents=[chunk],\n",
        "                metadatas=[{\"source\": pdf_path, \"chunk_id\": i, \"type\": \"pdf\"}],\n",
        "                ids=[f\"pdf_chunk_{i}_{os.path.basename(pdf_path)}\"]\n",
        "            )\n",
        "\n",
        "        # Log to LangSmith\n",
        "        if langsmith_client:\n",
        "            try:\n",
        "                langsmith_client.create_feedback(\n",
        "                    run_id=None,  # Will be associated with current trace\n",
        "                    key=\"pdf_processing\",\n",
        "                    score=1.0,\n",
        "                    comment=f\"Processed {len(chunks)} chunks from {pdf_path}\"\n",
        "                )\n",
        "            except Exception as e:\n",
        "                print(f\"LangSmith logging error: {e}\")\n",
        "\n",
        "        return f\"âœ… Successfully loaded {len(chunks)} chunks from {pdf_path}\"\n",
        "    except Exception as e:\n",
        "        return f\"âŒ Error: {str(e)}\""
      ],
      "metadata": {
        "id": "-zm5JRQUq7eE"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@traceable_function\n",
        "def get_relevant_context(query, n_results=3):\n",
        "    \"\"\"Retrieve relevant context from PDF knowledge base\"\"\"\n",
        "    try:\n",
        "        results = pdf_collection.query(\n",
        "            query_texts=[query],\n",
        "            n_results=n_results\n",
        "        )\n",
        "        return \"\\n\\n\".join(results['documents'][0]) if results['documents'] else \"\"\n",
        "    except Exception as e:\n",
        "        print(f\"PDF context query error: {e}\")\n",
        "        return \"\""
      ],
      "metadata": {
        "id": "nDXOc2XCq-Bn"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@traceable_function\n",
        "def store_conversation_memory(user_message, bot_response, conversation_context=\"\"):\n",
        "    \"\"\"Store conversation in long-term memory\"\"\"\n",
        "    try:\n",
        "        # Create a memory entry\n",
        "        memory_id = str(uuid.uuid4())\n",
        "        timestamp = datetime.now().isoformat()\n",
        "\n",
        "        # Combine user message and bot response for semantic search\n",
        "        memory_text = f\"User: {user_message}\\nBot: {bot_response}\"\n",
        "\n",
        "        if conversation_context:\n",
        "            memory_text = f\"Context: {conversation_context}\\n{memory_text}\"\n",
        "\n",
        "        # Store in memory collection\n",
        "        memory_collection.add(\n",
        "            documents=[memory_text],\n",
        "            metadatas=[{\n",
        "                \"type\": \"conversation\",\n",
        "                \"timestamp\": timestamp,\n",
        "                \"user_message\": user_message,\n",
        "                \"bot_response\": bot_response,\n",
        "                \"conversation_context\": conversation_context\n",
        "            }],\n",
        "            ids=[memory_id]\n",
        "        )\n",
        "\n",
        "        return True\n",
        "    except Exception as e:\n",
        "        print(f\"Memory storage error: {e}\")\n",
        "        return False"
      ],
      "metadata": {
        "id": "KfSlFGQByn1G"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@traceable_function\n",
        "def get_relevant_memories(query, n_results=2):\n",
        "    \"\"\"Retrieve relevant past conversations from memory\"\"\"\n",
        "    try:\n",
        "        results = memory_collection.query(\n",
        "            query_texts=[query],\n",
        "            n_results=n_results\n",
        "        )\n",
        "\n",
        "        memories = []\n",
        "        if results['documents']:\n",
        "            for i, doc in enumerate(results['documents'][0]):\n",
        "                metadata = results['metadatas'][0][i]\n",
        "                memory_text = f\"Previous conversation ({metadata['timestamp'][:10]}): {doc}\"\n",
        "                memories.append(memory_text)\n",
        "\n",
        "        return \"\\n\\n\".join(memories) if memories else \"\"\n",
        "    except Exception as e:\n",
        "        print(f\"Memory retrieval error: {e}\")\n",
        "        return \"\""
      ],
      "metadata": {
        "id": "F4oC-8_qzQKO"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@traceable_function\n",
        "def get_conversation_summary(history):\n",
        "    \"\"\"Generate a summary of the current conversation context\"\"\"\n",
        "    if not history:\n",
        "        return \"\"\n",
        "\n",
        "    # Take last few exchanges for context\n",
        "    recent_history = history[-3:] if len(history) > 3 else history\n",
        "    context_parts = []\n",
        "\n",
        "    for exchange in recent_history:\n",
        "        if isinstance(exchange, tuple) and len(exchange) == 2:\n",
        "            user_msg, bot_msg = exchange\n",
        "            context_parts.append(f\"User: {user_msg}\")\n",
        "            context_parts.append(f\"Bot: {bot_msg}\")\n",
        "        elif isinstance(exchange, list) and len(exchange) == 2:\n",
        "            user_msg, bot_msg = exchange\n",
        "            context_parts.append(f\"User: {user_msg}\")\n",
        "            context_parts.append(f\"Bot: {bot_msg}\")\n",
        "\n",
        "    return \"\\n\".join(context_parts)"
      ],
      "metadata": {
        "id": "z9yr1AOdyulc"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@traceable_function\n",
        "def is_pdf_context_relevant(pdf_context, query):\n",
        "    \"\"\"Check if PDF context is actually relevant to the query\"\"\"\n",
        "    if not pdf_context or len(pdf_context.strip()) < 50:\n",
        "        return False\n",
        "\n",
        "    # Check for common irrelevant patterns in PDF context\n",
        "    irrelevant_patterns = [\n",
        "        \"table of contents\", \"copyright\", \"abstract\", \"references\",\n",
        "        \"appendix\", \"index\", \"acknowledg\", \"preface\"\n",
        "    ]\n",
        "\n",
        "    pdf_lower = pdf_context.lower()\n",
        "    query_lower = query.lower()\n",
        "\n",
        "    # If PDF context contains many irrelevant sections, it's likely not useful\n",
        "    irrelevant_count = sum(1 for pattern in irrelevant_patterns if pattern in pdf_lower)\n",
        "    if irrelevant_count > 2:\n",
        "        return False\n",
        "\n",
        "    # Check if query terms actually appear in the context\n",
        "    query_terms = query_lower.split()\n",
        "    relevant_terms = sum(1 for term in query_terms if len(term) > 3 and term in pdf_lower)\n",
        "\n",
        "    # If less than 30% of meaningful query terms are in context, consider it irrelevant\n",
        "    meaningful_terms = [term for term in query_terms if len(term) > 3]\n",
        "    if meaningful_terms and (relevant_terms / len(meaningful_terms)) < 0.3:\n",
        "        return False\n",
        "\n",
        "    return True"
      ],
      "metadata": {
        "id": "B-dSs5KkrEY5"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@traceable_function\n",
        "def search_with_tavily(query):\n",
        "    \"\"\"Search using Tavily and get content from first result\"\"\"\n",
        "    if not TAVILY_AVAILABLE:\n",
        "        return \"Web search unavailable. Please install tavily-python: pip install tavily-python\"\n",
        "\n",
        "    try:\n",
        "        # Search for the query\n",
        "        search_response = tavily_client.search(\n",
        "            query=query,\n",
        "            search_depth=\"basic\",\n",
        "            max_results=3\n",
        "        )\n",
        "\n",
        "        if not search_response.get('results'):\n",
        "            return \"No search results found.\"\n",
        "\n",
        "        # Get the first result\n",
        "        first_result = search_response['results'][0]\n",
        "        first_url = first_result.get('url', '')\n",
        "\n",
        "        # Use Tavily's content if available\n",
        "        content = first_result.get('content', '')\n",
        "\n",
        "        if not content:\n",
        "            content = f\"Title: {first_result.get('title', 'N/A')}\\nURL: {first_url}\"\n",
        "\n",
        "        # Check if it's a PDF\n",
        "        if first_url.lower().endswith('.pdf'):\n",
        "            return f\"ðŸ“„ PDF Source: {first_url}\\n\\nThis appears to be a PDF document. Please visit the link to view the PDF: {first_url}\"\n",
        "\n",
        "        return f\"ðŸ” Search Result from: {first_url}\\n\\n{content}\"\n",
        "\n",
        "    except Exception as e:\n",
        "        return f\"âŒ Search error: {str(e)}\""
      ],
      "metadata": {
        "id": "oCpxqZxerIN5"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def apply_keyword_safety_check(user_message, bot_response):\n",
        "    \"\"\"Fallback keyword-based safety check\"\"\"\n",
        "    harmful_keywords = [\n",
        "        \"bomb\", \"weapon\", \"explosive\", \"harmful\", \"dangerous\", \"illegal\",\n",
        "        \"hack\", \"cheat\", \"bypass\", \"malicious\", \"violence\", \"hurt\", \"kill\"\n",
        "    ]\n",
        "\n",
        "    user_lower = user_message.lower()\n",
        "    response_lower = bot_response.lower()\n",
        "\n",
        "    # Check for harmful content in user message\n",
        "    if any(keyword in user_lower for keyword in harmful_keywords):\n",
        "        safety_message = \"I apologize, but I cannot engage with that type of question. I'm here to help with physics education and related scientific topics.\"\n",
        "        return safety_message, \"ðŸ›¡ï¸ Input blocked by safety check\"\n",
        "\n",
        "    # Check for harmful content in bot response\n",
        "    if any(keyword in response_lower for keyword in harmful_keywords):\n",
        "        safety_message = \"I need to provide a safe and educational response. Let me rephrase that to focus on the educational aspects of physics.\"\n",
        "        return safety_message, \"ðŸ›¡ï¸ Response moderated by safety check\"\n",
        "\n",
        "    return bot_response, \"ðŸ›¡ï¸ Safety check passed\""
      ],
      "metadata": {
        "id": "2MUya1Hor317"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@traceable_function\n",
        "def apply_safety_guardrails(user_message, bot_response):\n",
        "    \"\"\"Apply NeMo Guardrails for safety and content filtering\"\"\"\n",
        "    if not NEMO_GUARDRAILS_AVAILABLE:\n",
        "        return bot_response, \"âš ï¸ Guardrails disabled\"\n",
        "\n",
        "    try:\n",
        "        # Use NeMo Guardrails for safety checking\n",
        "        guarded_response = nemo_rails.generate(\n",
        "            messages=[{\"role\": \"user\", \"content\": user_message}]\n",
        "        )\n",
        "\n",
        "        # If guardrails modified the response, use the guarded version\n",
        "        if guarded_response and guarded_response != bot_response:\n",
        "            return guarded_response, \"ðŸ›¡ï¸ Response moderated by guardrails\"\n",
        "\n",
        "        return bot_response, \"ðŸ›¡ï¸ Safety check passed\"\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Guardrails error: {e}\")\n",
        "        # Fallback to keyword-based safety check\n",
        "        return apply_keyword_safety_check(user_message, bot_response)"
      ],
      "metadata": {
        "id": "cFg5B6W7rys8"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@traceable_function\n",
        "def check_educational_context(user_message):\n",
        "    \"\"\"Check if the query is appropriate for educational physics context\"\"\"\n",
        "    inappropriate_topics = [\n",
        "        \"harmful\", \"dangerous\", \"illegal\", \"weapon\", \"explosive\",\n",
        "        \"hack\", \"cheat\", \"bypass\", \"circumvent\", \"malicious\"\n",
        "    ]\n",
        "\n",
        "    user_lower = user_message.lower()\n",
        "\n",
        "    # Check for potentially harmful topics\n",
        "    for topic in inappropriate_topics:\n",
        "        if topic in user_lower:\n",
        "            return False, f\"This appears to be asking about {topic} topics, which I cannot assist with for safety reasons.\"\n",
        "\n",
        "    # Check if it's physics-related or general educational\n",
        "    physics_terms = [\n",
        "        \"physics\", \"quantum\", \"mechanics\", \"thermodynamics\", \"electromagnetism\",\n",
        "        \"relativity\", \"optics\", \"atomic\", \"nuclear\", \"particle\", \"force\",\n",
        "        \"energy\", \"motion\", \"velocity\", \"acceleration\", \"gravity\", \"electric\",\n",
        "        \"magnetic\", \"wave\", \"light\", \"sound\", \"heat\", \"temperature\"\n",
        "    ]\n",
        "\n",
        "    # Allow general educational questions too\n",
        "    educational_terms = [\n",
        "        \"science\", \"math\", \"chemistry\", \"biology\", \"astronomy\", \"engineering\",\n",
        "        \"technology\", \"computer\", \"programming\", \"learn\", \"study\", \"education\",\n",
        "        \"explain\", \"how does\", \"what is\", \"why does\"\n",
        "    ]\n",
        "\n",
        "    has_physics_term = any(term in user_lower for term in physics_terms)\n",
        "    has_educational_term = any(term in user_lower for term in educational_terms)\n",
        "\n",
        "    if not (has_physics_term or has_educational_term):\n",
        "        return False, \"I specialize in physics and educational topics. Please ask questions related to science, education, or general knowledge.\"\n",
        "\n",
        "    return True, \"OK\""
      ],
      "metadata": {
        "id": "9j2jW5rRr7NN"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@traceable_function\n",
        "def chat_with_physics_bot(message, history):\n",
        "    \"\"\"Main chat function with comprehensive tracing and token tracking\"\"\"\n",
        "\n",
        "    # Create a unique run ID for this conversation\n",
        "    run_id = str(uuid.uuid4())\n",
        "\n",
        "    # Log conversation start\n",
        "    if langsmith_client:\n",
        "        try:\n",
        "            langsmith_client.create_feedback(\n",
        "                run_id=run_id,\n",
        "                key=\"conversation_start\",\n",
        "                score=1.0,\n",
        "                comment=f\"User message: {message[:100]}...\"\n",
        "            )\n",
        "        except Exception as e:\n",
        "            print(f\"LangSmith logging error: {e}\")\n",
        "\n",
        "    # First check educational context\n",
        "    is_appropriate, context_message = check_educational_context(message)\n",
        "    if not is_appropriate:\n",
        "        return f\"ðŸ›¡ï¸ Educational Context Check:\\n\\n{context_message}\"\n",
        "\n",
        "    # Get relevant context from different sources\n",
        "    pdf_context = get_relevant_context(message)\n",
        "    memory_context = get_relevant_memories(message)\n",
        "    conversation_context = get_conversation_summary(history)\n",
        "\n",
        "    # Check if PDF context is actually relevant\n",
        "    use_pdf = is_pdf_context_relevant(pdf_context, message)\n",
        "\n",
        "    system_prompt = \"\"\"You are a friendly Physics Teacher Bot with memory. Follow these rules:\n",
        "    1. Use the provided context from PDFs, past conversations, and search results to answer questions accurately\n",
        "    2. If the context doesn't fully answer the question, use your knowledge to provide a complete answer\n",
        "    3. Reference past conversations when relevant to provide continuity\n",
        "    4. Be educational and clear in your explanations\n",
        "    5. Maintain context from the current conversation flow\n",
        "    6. Always prioritize safety and educational value in your responses\"\"\"\n",
        "\n",
        "    # Build context sections\n",
        "    context_sections = []\n",
        "    source_notes = []\n",
        "\n",
        "    if use_pdf:\n",
        "        context_sections.append(f\"PDF Knowledge:\\n{pdf_context}\")\n",
        "        source_notes.append(\"ðŸ“š PDF\")\n",
        "\n",
        "    if memory_context:\n",
        "        context_sections.append(f\"Past Conversations:\\n{memory_context}\")\n",
        "        source_notes.append(\"ðŸ’­ Memory\")\n",
        "\n",
        "    if conversation_context:\n",
        "        context_sections.append(f\"Current Conversation:\\n{conversation_context}\")\n",
        "\n",
        "    # If no PDF context is relevant, use web search\n",
        "    if not use_pdf:\n",
        "        search_results = search_with_tavily(message)\n",
        "        context_sections.append(f\"Web Search:\\n{search_results}\")\n",
        "        source_notes.append(\"ðŸ” Web\")\n",
        "\n",
        "    # Combine all contexts\n",
        "    combined_context = \"\\n\\n\".join(context_sections) if context_sections else \"No specific context available.\"\n",
        "    source_note = \" + \".join(source_notes) if source_notes else \"General knowledge\"\n",
        "\n",
        "    user_content = f\"\"\"Available Context:\n",
        "{combined_context}\n",
        "\n",
        "Question: {message}\n",
        "\n",
        "Please provide a helpful, educational answer based on the available context above.\"\"\"\n",
        "\n",
        "    try:\n",
        "        response = client.chat.completions.create(\n",
        "            model=\"gpt-3.5-turbo\",\n",
        "            messages=[\n",
        "                {\"role\": \"system\", \"content\": system_prompt},\n",
        "                {\"role\": \"user\", \"content\": user_content}\n",
        "            ],\n",
        "            temperature=0.2\n",
        "        )\n",
        "\n",
        "        # Track token usage\n",
        "        token_tracker.update_from_response(response, \"gpt-3.5-turbo\")\n",
        "\n",
        "        bot_response = response.choices[0].message.content\n",
        "\n",
        "        # Apply safety guardrails\n",
        "        safe_response, safety_status = apply_safety_guardrails(message, bot_response)\n",
        "\n",
        "        # Store this conversation in long-term memory (only if safe)\n",
        "        if \"blocked\" not in safety_status.lower():\n",
        "            store_conversation_memory(message, safe_response, conversation_context)\n",
        "\n",
        "        # Log token usage and success\n",
        "        if langsmith_client:\n",
        "            try:\n",
        "                token_summary = token_tracker.get_summary()\n",
        "                langsmith_client.create_feedback(\n",
        "                    run_id=run_id,\n",
        "                    key=\"token_usage\",\n",
        "                    score=1.0,\n",
        "                    comment=json.dumps(token_summary)\n",
        "                )\n",
        "\n",
        "                langsmith_client.create_feedback(\n",
        "                    run_id=run_id,\n",
        "                    key=\"response_quality\",\n",
        "                    score=1.0,\n",
        "                    comment=f\"Sources: {source_note}, Safety: {safety_status}\"\n",
        "                )\n",
        "            except Exception as e:\n",
        "                print(f\"LangSmith logging error: {e}\")\n",
        "\n",
        "        # Add token usage to response\n",
        "        token_summary = token_tracker.get_summary()\n",
        "        token_info = f\" | Tokens: {token_summary['total_tokens']} (${token_summary['estimated_cost']})\"\n",
        "\n",
        "        return f\"ðŸ”® Sources: {source_note} | {safety_status}{token_info}\\n\\n{safe_response}\"\n",
        "\n",
        "    except Exception as e:\n",
        "        # Log error to LangSmith\n",
        "        if langsmith_client:\n",
        "            try:\n",
        "                langsmith_client.create_feedback(\n",
        "                    run_id=run_id,\n",
        "                    key=\"error\",\n",
        "                    score=0.0,\n",
        "                    comment=f\"Error generating response: {str(e)}\"\n",
        "                )\n",
        "            except Exception as e:\n",
        "                print(f\"LangSmith logging error: {e}\")\n",
        "\n",
        "        return f\"âŒ Error generating response: {str(e)}\""
      ],
      "metadata": {
        "id": "_HsNsC0JrNYX"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@traceable_function\n",
        "def clear_memory():\n",
        "    \"\"\"Clear all conversation memory\"\"\"\n",
        "    try:\n",
        "        memory_collection.delete(where={\"type\": {\"$ne\": \"\"}})\n",
        "\n",
        "        # Log memory clearance\n",
        "        if langsmith_client:\n",
        "            try:\n",
        "                langsmith_client.create_feedback(\n",
        "                    run_id=None,\n",
        "                    key=\"memory_cleared\",\n",
        "                    score=1.0,\n",
        "                    comment=\"All conversation memory cleared\"\n",
        "                )\n",
        "            except Exception as e:\n",
        "                print(f\"LangSmith logging error: {e}\")\n",
        "\n",
        "        return \"âœ… Conversation memory cleared successfully!\"\n",
        "    except Exception as e:\n",
        "        return f\"âŒ Error clearing memory: {str(e)}\""
      ],
      "metadata": {
        "id": "bojVEzNJzcql"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@traceable_function\n",
        "def export_memory():\n",
        "    \"\"\"Export conversation memory as JSON\"\"\"\n",
        "    try:\n",
        "        results = memory_collection.get()\n",
        "        memories = []\n",
        "\n",
        "        for i, doc in enumerate(results['documents']):\n",
        "            memories.append({\n",
        "                \"content\": doc,\n",
        "                \"metadata\": results['metadatas'][i],\n",
        "                \"id\": results['ids'][i]\n",
        "            })\n",
        "\n",
        "        filename = f\"conversation_memory_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json\"\n",
        "        with open(filename, 'w') as f:\n",
        "            json.dump(memories, f, indent=2)\n",
        "\n",
        "        # Log export\n",
        "        if langsmith_client:\n",
        "            try:\n",
        "                langsmith_client.create_feedback(\n",
        "                    run_id=None,\n",
        "                    key=\"memory_exported\",\n",
        "                    score=1.0,\n",
        "                    comment=f\"Exported {len(memories)} memories to {filename}\"\n",
        "                )\n",
        "            except Exception as e:\n",
        "                print(f\"LangSmith logging error: {e}\")\n",
        "\n",
        "        return f\"âœ… Memory exported to {filename}\"\n",
        "    except Exception as e:\n",
        "        return f\"âŒ Error exporting memory: {str(e)}\""
      ],
      "metadata": {
        "id": "k5T1f6fhzdpv"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_guardrails_status():\n",
        "    \"\"\"Get status of safety guardrails\"\"\"\n",
        "    if NEMO_GUARDRAILS_AVAILABLE and nemo_rails is not None:\n",
        "        return \"âœ… NVIDIA NeMo Guardrails: ACTIVE\"\n",
        "    else:\n",
        "        return \"âš ï¸ NVIDIA NeMo Guardrails: NOT AVAILABLE\"\n",
        "\n",
        "def get_token_usage():\n",
        "    \"\"\"Get current token usage statistics\"\"\"\n",
        "    summary = token_tracker.get_summary()\n",
        "    return f\"\"\"\n",
        "ðŸ“Š Token Usage Summary:\n",
        "â€¢ Total Tokens: {summary['total_tokens']:,}\n",
        "â€¢ Prompt Tokens: {summary['prompt_tokens']:,}\n",
        "â€¢ Completion Tokens: {summary['completion_tokens']:,}\n",
        "â€¢ Estimated Cost: ${summary['estimated_cost']}\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "EsJEfhyEsOkx"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def reset_token_tracking():\n",
        "    \"\"\"Reset token tracking counters\"\"\"\n",
        "    global token_tracker\n",
        "    token_tracker = TokenUsageTracker()\n",
        "    return \"âœ… Token tracking reset successfully!\""
      ],
      "metadata": {
        "id": "RXu4hXt1biYH"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_langsmith_status():\n",
        "    \"\"\"Get LangSmith tracing status\"\"\"\n",
        "    if LANGCHAIN_AVAILABLE:\n",
        "        return \"âœ… LangSmith Tracing: ACTIVE\"\n",
        "    else:\n",
        "        return \"âš ï¸ LangSmith Tracing: NOT AVAILABLE\""
      ],
      "metadata": {
        "id": "X9HsbgJVble6"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_pdf_and_chat(pdf_file, message, history):\n",
        "    # First store the PDF\n",
        "    result_msg = store_pdf_in_db(pdf_file.name)\n",
        "\n",
        "    # Then get response\n",
        "    response = chat_with_physics_bot(message, history)\n",
        "\n",
        "    return result_msg, response"
      ],
      "metadata": {
        "id": "nMkzyTidrWwn"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def launch_app():\n",
        "    with gr.Blocks() as demo:\n",
        "        gr.Markdown(\"# âš›ï¸ Physics Teacher Chat with PDF RAG + Web Search + Memory + Safety Guardrails + LangSmith Tracing\")\n",
        "\n",
        "        with gr.Row():\n",
        "            with gr.Column():\n",
        "                pdf_input = gr.File(label=\"Upload PDF\", file_types=[\".pdf\"])\n",
        "                load_btn = gr.Button(\"Load PDF into Knowledge Base\")\n",
        "                load_status = gr.Textbox(label=\"Load Status\", interactive=False)\n",
        "\n",
        "                gr.Markdown(\"### Safety & Memory Management\")\n",
        "                with gr.Row():\n",
        "                    clear_mem_btn = gr.Button(\"ðŸ§¹ Clear Memory\")\n",
        "                    export_mem_btn = gr.Button(\"ðŸ’¾ Export Memory\")\n",
        "                    safety_status_btn = gr.Button(\"ðŸ›¡ï¸ Safety Status\")\n",
        "                mem_status = gr.Textbox(label=\"Memory Status\", interactive=False)\n",
        "\n",
        "                gr.Markdown(\"### Token Usage Tracking\")\n",
        "                with gr.Row():\n",
        "                    token_stats_btn = gr.Button(\"ðŸ“Š Token Usage\")\n",
        "                    reset_tokens_btn = gr.Button(\"ðŸ”„ Reset Tracking\")\n",
        "                    tracing_status_btn = gr.Button(\"ðŸ” Tracing Status\")\n",
        "                token_status = gr.Textbox(label=\"Token Status\", interactive=False)\n",
        "\n",
        "                gr.Markdown(\"\"\"\n",
        "                ### How it works:\n",
        "                1. **Upload a PDF** - Answers prioritize PDF content when relevant\n",
        "                2. **Ask questions** - System uses PDF, web search, and past conversations\n",
        "                3. **Long-term memory** - Remembers past conversations for context\n",
        "                4. **Safety Guardrails** - NVIDIA NeMo Guardrails ensure safe, educational responses\n",
        "                5. **Multiple sources** - Combines PDF ðŸ“š, Web ðŸ”, and Memory ðŸ’­\n",
        "                6. **LangSmith Tracing** - Comprehensive tracing and token usage tracking\n",
        "                7. **Token Monitoring** - Real-time token usage and cost tracking\n",
        "                \"\"\")\n",
        "\n",
        "            with gr.Column():\n",
        "                chat_interface = gr.ChatInterface(\n",
        "                    fn=chat_with_physics_bot,\n",
        "                    title=\"Chat with Physics Bot (with Memory, Safety & Tracing)\",\n",
        "                    description=\"Ask questions about physics. I'll remember our past conversations, use multiple knowledge sources, ensure safe responses, and track token usage!\"\n",
        "                )\n",
        "\n",
        "        # Load PDF when button clicked\n",
        "        load_btn.click(\n",
        "            fn=lambda pdf: store_pdf_in_db(pdf.name) if pdf else \"Please upload a PDF first\",\n",
        "            inputs=[pdf_input],\n",
        "            outputs=[load_status]\n",
        "        )\n",
        "\n",
        "        # Memory management buttons\n",
        "        clear_mem_btn.click(\n",
        "            fn=clear_memory,\n",
        "            outputs=[mem_status]\n",
        "        )\n",
        "\n",
        "        export_mem_btn.click(\n",
        "            fn=export_memory,\n",
        "            outputs=[mem_status]\n",
        "        )\n",
        "\n",
        "        safety_status_btn.click(\n",
        "            fn=get_guardrails_status,\n",
        "            outputs=[mem_status]\n",
        "        )\n",
        "\n",
        "        # Token tracking buttons\n",
        "        token_stats_btn.click(\n",
        "            fn=get_token_usage,\n",
        "            outputs=[token_status]\n",
        "        )\n",
        "\n",
        "        reset_tokens_btn.click(\n",
        "            fn=reset_token_tracking,\n",
        "            outputs=[token_status]\n",
        "        )\n",
        "\n",
        "        tracing_status_btn.click(\n",
        "            fn=get_langsmith_status,\n",
        "            outputs=[token_status]\n",
        "        )\n",
        "\n",
        "    demo.launch()\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Check for required API keys\n",
        "    if not os.getenv(\"OPENAI_API_KEY\"):\n",
        "        print(\"âŒ OPENAI_API_KEY not found in environment variables\")\n",
        "        exit(1)\n",
        "\n",
        "    if not os.getenv(\"TAVILY_API_KEY\") and TAVILY_AVAILABLE:\n",
        "        print(\"âŒ TAVILY_API_KEY not found in environment variables\")\n",
        "        print(\"Please get your free API key from: https://app.tavily.com/\")\n",
        "        print(\"Continuing without web search functionality...\")\n",
        "\n",
        "    # Check for LangSmith API key\n",
        "    if not os.getenv(\"LANGCHAIN_API_KEY\"):\n",
        "        print(\"âš ï¸  LANGCHAIN_API_KEY not found. LangSmith tracing will be disabled.\")\n",
        "        print(\"ðŸ’¡ Get your free API key from: https://smith.langchain.com/\")\n",
        "\n",
        "    # Auto-load PDF if exists\n",
        "    pdf_files = [f for f in os.listdir('.') if f.endswith('.pdf')]\n",
        "    if pdf_files:\n",
        "        print(f\"Found PDF: {pdf_files[0]}\")\n",
        "        store_pdf_in_db(pdf_files[0])\n",
        "\n",
        "    print(\"ðŸ§  Long-term memory enabled!\")\n",
        "    print(\"ðŸ“Š Token usage tracking enabled!\")\n",
        "    print(get_guardrails_status())\n",
        "    print(get_langsmith_status())\n",
        "\n",
        "    if LANGCHAIN_AVAILABLE:\n",
        "        print(\"ðŸ” LangSmith tracing enabled! Visit https://smith.langchain.com/ to view traces.\")\n",
        "\n",
        "    launch_app()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 782
        },
        "id": "iBiQBI3urYoG",
        "outputId": "5324fe21-6674-4c29-ab77-4cea8e2efdc7"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸ§  Long-term memory enabled!\n",
            "ðŸ“Š Token usage tracking enabled!\n",
            "âœ… NVIDIA NeMo Guardrails: ACTIVE\n",
            "âœ… LangSmith Tracing: ACTIVE\n",
            "ðŸ” LangSmith tracing enabled! Visit https://smith.langchain.com/ to view traces.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/gradio/chat_interface.py:347: UserWarning: The 'tuples' format for chatbot messages is deprecated and will be removed in a future version of Gradio. Please set type='messages' instead, which uses openai-style 'role' and 'content' keys.\n",
            "  self.chatbot = Chatbot(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "It looks like you are running Gradio on a hosted Jupyter notebook, which requires `share=True`. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://78dc615efcbf066159.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://78dc615efcbf066159.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ofwGV-RJtYJE"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}